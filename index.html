<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <title>XAIP-Workshops by KCL-Planning</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
      
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">XAIP Workshops</h1>
      <a href="https://kcl-planning.github.io/XAIP-Workshops/" class="btn">Home</a>
      <a href="https://kcl-planning.github.io/XAIP-Workshops/related_work" class="btn">Related Work</a>
      <a href="https://kcl-planning.github.io/XAIP-Workshops/contact" class="btn">Contact</a>
      <a href="https://github.com/KCL-Planning/XAIP-Workshops/" class="btn">View on GitHub</a>

    </section>

    <section class="main-content">
      <p>Explainable Artificial Intelligence (XAI) concerns the challenge of shedding light on opaque models where transparency is important, e.g. in analysis or synthesis tasks. In particular, as AI is increasingly being adopted for deployed applications, the challenge of supporting interaction with humans is becoming more apparent. Partly this is to support collaborations with humans but also it is a necessary step in the process of building trust as humans migrate greater competence and responsibility to AI systems. The challenge is to find effective ways to characterize and communicate the foundations of AI-driven behavior when the algorithms that drive it are far from transparent to humans. While XAI at large is primarily concerned with learning-based approaches, model-based <strong>Explainable AI Planning (XAIP)</strong> can play an important role in addressing complex decision-making procedures.</p>
      <p></p>
      <h3>ICAPS Workshops</h3>
      <p></p>
     
      <ul><li>
      <b>2019 ICAPS XAIP Workshop</b><br><br>
        <ul>
          <li><b>Mission:</b><br><font size="-1"> </font></li><br>
          <li><b>Topics</b> (including but not limited to):<br><font size="-1"><ul>
            <li></li>
            <li></li>
            <li></li>
            <li></li>
            <li></li>
            <li></li>
            <li></li>
            <li></li>
            </ul></font></li><br>
          <li><b>Important Dates:</b><br><font size="-1"><ul>
            <li>Paper submission: </li>
            <li>Notification: </li>
            <li>Camera-ready submission: </li>
            <li>Date of Workshop: </li>
            </ul></font></li><br>
          <li><b>Invited Speaker:</b><br><font size="-1"><b></b>,</font></li><br>
          <li><b>Program:</b><br><font size="-1">
            <b>Time </b> <br>
            </font></li><br>
          <li><b>Proceedings:</b><br><font size="-1">The proceedings can be found <a href="https://nms.kcl.ac.uk/daniele.magazzeni/XAIP18_proceedings.pdf">here</a>.</font></li><br>
          <li><b>Organizing Chairs:</b><br></li>
          <li><b>Program Committee:</b></li>
        </ul>
      <br>See the workshop <a href="https://icaps19.icaps-conference.org/workshops/XAIP/index.html">webpage</a> for more information.
      </li></ul>
   
   
      
      <ul><li>
      <b>2018 ICAPS XAIP Workshop</b><br><br>
        <ul>
          <li><b>Mission:</b><br><font size="-1"> As AI is increasingly being adopted into application solutions, the challenge of supporting interaction with humans is becoming more apparent. Partly this is to support integrated working styles, in which humans and intelligent systems cooperate in problem-solving, but it is also a necessary step in the process of building trust as humans invest greater authority and responsibility in intelligent systems. Explainability poses challenges for many types of AI systems, including planning and scheduling (PS) systems. For example, how should a PS system justify that a plan or schedule is correct, or good, or respects supplied preferences? How can the PS system explain particular steps, ordering decisions, or resource choices? How can a PS system explain that no solution is possible, or what relaxations of the constraints would allow a solution? How can a PS system respond to questions like “what is the hard part?” or “why is this taking so long?”. These are all difficult questions that can require analysis of plan or schedule structure, analysis of the goals, constraints, and preferences, and potentially hypothetical reasoning.</font></li><br>
          <li><b>Topics</b> (including but not limited to):<br><font size="-1"><ul>
            <li>representation, organization, and knowledge needed for explanation;</li>
            <li>the creation of such content during plan generation and understanding;</li>
            <li>generation and evaluation of explanations;</li>
            <li>the way in which explanations are communicated to humans (e.g., plan summaries, answers to questions);</li>
            <li>the role of knowledge and learning in explainable planners;</li>
            <li>human vs AI models in explanations;</li>
            <li>links between explainable planning and other disciplines (e.g., social science, argumentation);</li>
            <li>use cases and applications of explainable planning</li>
            </ul></font></li><br>
          <li><b>Important Dates:</b><br><font size="-1"><ul>
            <li>Paper submission: April 6, 2018</li>
            <li>Notification: April 26, 2018</li>
            <li>Camera-ready submission: May 25, 2018</li>
            <li>Date of Workshop: June 25, 2018</li>
            </ul></font></li><br>
          <li><b>Invited Speaker:</b><br><font size="-1"><b>David Aha</b>, Naval Research Laboratory</font></li><br>
          <li><b>Program:</b><br><font size="-1">
            <b>9:00 </b> &nbsp Welcome and Introduction<br>
            <b>9:10 </b> &nbsp Invited Talk: Relating XAI (Explainable AI) to XAIP (Explainable Planning), <i>David Aha.</i><br>
            <b>10:10</b> &nbsp Human-Aware Planning Revisited: A Tale of Three Models, <i>Tathagata Chakraborti, Sarath Sreedharan, and Subbarao Kambhampati.</i><br>
            <b>10:30</b> &nbsp Coffee Break<br>
            <b>11:00</b> &nbsp Explaining Rebel Behavior in Goal Reasoning Agents, <i>Dustin Dannenhauer, Michael Floyd, Daniele Magazzeni, and David Aha.</i><br>
            <b>11:20</b> &nbsp Action Selection for Transparent Planning, <i>Aleck Macnally, Nir Lipovetzky, Miquel Ramírez, and Adrian Pearce.</i><br>
            <b>11:40</b> &nbsp Moral Permissibility of Action Plans, <i>Felix Lindner, Robert Mattmüller, and Bernhard Nebel.</i><br>
            <b>12:00</b> &nbsp Explaining Agents Plans with Valuings, <i>Michael Winikoff, Virginia Dignum, and Frank Dignum</i><br>
            <b>12:20</b> &nbsp Lunch<br>
            <b>13:40</b> &nbsp Explicability as Minimizing Distance from Expected Behavior, <i>Anagha Kulkarni, Yu Zhang, Tathagata Chakraborti, and Subbarao Kambhampati.</i><br>
            <b>14:00</b> &nbsp Generating Explanations for Mathematical Optimisation: Solution Framework and Case Study, <i>Christina Burt, Katerina Klimova, and Bernhard Primas.</i><br>
            <b>14:20</b> &nbsp What was I planning to do?, <i>Mark Roberts, Isaac Monteath, Raymond Sheh, David Aha, Piyabutra Jampathom, Keith Akins, Eric Sydow, Vikas Shivashankar, and Claude Sammut.</i><br>
            <b>14:40</b> &nbsp Plan Explanation Through Search in an Abstract Model Space: Extended Results, <i>Sarath Sreedharan, Midhun Pookkottil Madhusoodanan, Siddharth Srivastava, and Subbarao Kambhampati</i><br>
            <b>15:00</b> &nbsp Coffee Break<br>
            <b>15:30</b> &nbsp Challenges in Explainable Planning for Space Operations, <i>Simone Fratini and Nicola Policella</i><br>
            <b>15:50</b> &nbsp Improving Explanation and Effectiveness of Interactions among Autonomous Vehicles and Pedestrians, <i>Sara Manzoni, Simone Fontana, Andrea Gorrini, Domenico G. Sorrenti, and Stefania Bandini</i><br>
            <b>16:10</b> &nbsp Visualizations for an Explainable Planning Agent, <i>Tathagata Chakraborti, Kshitij Fadnis, Kartik Talamadupula, Mishal Dholakia, Biplav Srivastava, Jeffrey O. Kephart, and Rachel K. E. Bellamy</i><br>
            <b>16:30</b> &nbsp Towards Explanation-Supportive Knowledge Engineering for Planning, <i>Mauro Vallati, Lee Mccluskey, and Lukas Chrpa</i><br>
            </font></li><br>
          <li><b>Proceedings:</b><br><font size="-1">The proceedings can be found <a href="https://nms.kcl.ac.uk/daniele.magazzeni/XAIP18_proceedings.pdf">here</a>.</font></li><br>
          <li><b>Organizing Chairs:</b><br><font size="-1"><ul>
            <li>Susanne Biundo, Ulm University</li>
            <li>Pat Langley, University of Auckland</li>
            <li>Daniele Magazzeni, King’s College London</li>
            <li>David Smith</li>
          </font></li><br>
          <li><b>Program Committee:</b><br><font size="-1"><ul>
            <li>Susanne Biundo (University of Ulm)</li>
            <li>John Bresina (NASA)</li>
            <li>Tathagata Chakraborti (Arizona State University)</li>
            <li>Dustin	Dannenhauer (Naval Research Laboratory)</li>
            <li>Jeremy Frank (NASA)</li>
            <li>Pat Langley (University of Auckland)</li>
            <li>Daniele Magazzeni (King’s College London)</li>
            <li>Matthew Molineaux (Knexus Research Corporation)</li>
            <li>Mark Roberts (Naval Research Laboratory)</li>
            <li>David Smith</li>
            <li>Siddharth Srivastava	(ASU)</li>
            <li>Kartik	Talamadupula (IBM)</li>
          </font></li><br>
        </ul>
      <br>See the workshop <a href="http://icaps18.icaps-conference.org/xaip/index.html">webpage</a> for more information.
      </li></ul>
      
      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/KCL-Planning/XAIP-Workshops">XAIP Workshops</a> is maintained by <a href="https://github.com/KCL-Planning">KCL-Planning</a>.</span>
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>
    </section>
  </body>
</html>
