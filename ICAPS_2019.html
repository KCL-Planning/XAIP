<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <title>XAIP-Workshops by KCL-Planning</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
      
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">XAIP Workshops</h1>
      <a href="https://kcl-planning.github.io/XAIP-Workshops/index.html" class="btn">Home</a>
      <a href="https://kcl-planning.github.io/XAIP-Workshops/ICAPS_2019" class="btn">ICAPS 2019</a>
      <a href="https://kcl-planning.github.io/XAIP-Workshops/archive" class="btn">Archive</a>
      <a href="https://kcl-planning.github.io/XAIP-Workshops/related_work" class="btn">Related Work</a>
      <a href="https://kcl-planning.github.io/XAIP-Workshops/contact" class="btn">Contact</a>
   
    </section>

    <section class="main-content">
     
     <center>
      <h1 id="icaps19"><b>2nd ICAPS Workshop on Explainable Planning (XAIP-2019)</b></h1> <h3>Berkeley, CA, 11-12 July 2019.</h3>
    </center>       
          <h2><b>Mission:</b></h2><p>Explainable Artificial Intelligence (XAI) concerns the challenge of shedding light on opaque models in contexts for which transparency is important, i.e. where these models could be used to solve analysis or synthesis tasks. In particular, as AI is increasingly being adopted into application solutions, the challenge of supporting interaction with humans is becoming more apparent. Partly this is to support integrated working styles, in which humans and intelligent systems cooperate in problem-solving, but also it is a necessary step in the process of building trust as humans migrate greater competence and responsibility to such systems. The challenge is to find effective ways to characterise, and to communicate, the foundations of AI-driven behaviour, when the algorithms that drive it are far from transparent to humans. While XAI at large is primarily concerned with learning-based approaches, model-based approaches are well suited -- arguably better suited -- for explanation, and Explainable AI Planning (XAIP) can play an important role in addressing complex decision-making procedures. <br><br>
            After the success of previous workshops on XAI and XAIP, the mission of this workshop is to mature and broaden the XAIP community, fostering continued exchange on XAIP topics at ICAPS.</p></li>
          <h2><b>Topics</b></h2> <p>
            Topics of interest include (but are not limited to):
            <ul>
            <li>Frameworks for defining meaningful explanations in planning and scheduling contexts;</li>
            <li>Representation, organization, and memory content used in explanation;</li>
            <li>The creation of such content during plan generation or understanding;</li>
            <li>Generation and evaluation of explanations;</li>
            <li>The explanation process, i.e. the way in which explanations are communicated to humans (e.g., plan summaries, answers to questions);</li>
            <li>The role of knowledge and learning in explainable planners;</li>
            <li>Human vs AI models in explanations;</li>
            <li>Links between explainable planning and other disciplines (e.g. social science, argumentation);</li>
            <li>Model differences and model reconciliation;</li>
            <li>Goal reasoning and plan explanations;</li>
            <li>Excuse generation, unsolvability and explanations;</li>
            <li>Use cases and applications of explainable planning.</li>
            </ul></p></li>
          <h2><b>Important Dates:</b></h2><p>
            <li>Paper submission: <b>March 22, 2019 (UTC-12)</b></li>
            <li>Notification: April 19, 2019</li>
            <li>Camera-ready submission: May 31, 2019</li>
            <li>Date of Workshop: July 11 or 12, 2019</li>
            </ul></p></li><br>

          <h2><b>Invited Speaker:</b></h2><p><b>TBD</b></p></li>
          <h2><b>Program:</b></h2><p>
            <b>TBD</b> 
            </p></li>

          <h2><b>Organizing Chairs:</b></h2><p><ul>
            <li>Tathagata Chakraborti (IBM Research AI, USA)</li>
            <li>Dustin Dannenhauer (Naval Research Laboratory, USA)</li>
            <li>Joerg Hoffmann (Saarland University, Germany)</li>
            <li>Daniele Magazzeni (King's College London, UK)</li>
            </ul></p></li>
          <h2><b>Program Committee:</b></h2><p><b>TBD</b></p></li><br>
        
   
      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/KCL-Planning/XAIP-Workshops">XAIP Workshops</a> is maintained by <a href="https://github.com/KCL-Planning">KCL-Planning</a>.</span>
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>
    </section>
  </body>
</html>
